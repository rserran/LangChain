{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7197fb70",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "LangChain is a framework for developing applications powered by language models. It enables applications that are:\n",
    "\n",
    "Data-aware: connect a language model to other sources of data\n",
    "\n",
    "Agentic: allow a language model to interact with its environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873c6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4272fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "816e5ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nDulha Fashions.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What is a good company name for a company that makes Indian bridal wears for mens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633d75cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='मुझे टीवी पर फिल्में और खेल देखना पसंद है।', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "chat.predict_messages([HumanMessage(content=\"Translate this sentence from English to Hindi. I love watching movies and sports on TV.\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b7c092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मुझे टीवी पर फिल्में और खेल देखना पसंद है।'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"Translate this sentence from English to Hindi. I love watching movies and sports on TV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be7575d",
   "metadata": {},
   "source": [
    "# Prompt templates\n",
    "LLM add the user input to a larger piece of text, called a prompt template, that provides additional context on the specific task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88dac05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'California Indians'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict('What is a good team name for cricket franchise of USA Premier League in Californai? Name should be close to Indians')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0118158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good team name for cricket franchise of USA Premier League California? Name should be close to Indians'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good team name for cricket franchise of USA Premier League {city}? Name should be close to Indians\")\n",
    "prompt.format(city=\"California\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183aa11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCalifornia Kings'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(\"California\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550567a",
   "metadata": {},
   "source": [
    "# Chains\n",
    "Chains allow us to combine multiple components together to create a single, coherent application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a94d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb983b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGolden Warriors of California.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"California\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b2d8b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sari Couture Designs.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\", \"category\"],\n",
    "    template=\"What is a good company name for a company that makes {product} for {category}?\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run({\n",
    "    'product': \"Indian bridal wears\",\n",
    "    'category': \"womens\"\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13cbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eda24aba",
   "metadata": {},
   "source": [
    "# Agents\n",
    "To handle complex workflows, we need to be able to dynamically choose actions based on inputs. Agents help you to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb9aff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-search-results) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267d3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# The language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce29edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the temperature in Fahrenheit and then use a calculator to raise it to the .023 power.\n",
      "Action: Search\n",
      "Action Input: \"High temperature in Mumbai yesterday in Fahrenheit\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMumbai Weather History for the Previous 24 Hours ; 82 °F · 81 °F · 79 °F ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to use a calculator to raise 82 to the .023 power\n",
      "Action: Calculator\n",
      "Action Input: 82^.023\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1.1066689335946365\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1.1066689335946365\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.1066689335946365'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it out!\n",
    "agent.run(\"What was the high temperature in Mumbai yesterday in Fahrenheit? What is that number raised to the .023 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05dc4f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the number of wickets taken by Ashwin\n",
      "Action: Search\n",
      "Action Input: \"Ravichandran Ashwin wickets West Indies test match\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBeside 5-60 from the first innings, Ashwin's dozen wickets in the match gave him an eighth 10-wicket haul in a test, tying Anil Kumble's India record. They are tied for fifth on the all-time list. Jadeja took 2-38 on Friday for a match haul of five wickets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out if the number of wickets is a prime number\n",
      "Action: Calculator\n",
      "Action Input: 12\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 12\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ravichandran Ashwin took 12 wickets against West Indies in the current test match, and 12 is not a prime number.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ravichandran Ashwin took 12 wickets against West Indies in the current test match, and 12 is not a prime number.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many wickets Ravichandran Ashwin took against West Indies in current test match? Is it prime number?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf09ca",
   "metadata": {},
   "source": [
    "# Memory\n",
    "The chains and agents are stateless, but for many applications, it's necessary to reference past interactions. The Memory module gives you a way to maintain the application state. \n",
    "For example, chatbots, where you want to understand new messages in the context of past messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aea1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: My name is Sanjay, I am currently staying Pune. I have done BE in Computer\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi Sanjay, it's nice to meet you. I'm an AI and I'm programmed to answer questions about Pune. Can I help you with anything?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.run(\"My name is Sanjay, I am currently staying Pune. I have done BE in Computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb5115df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Sanjay, I am currently staying Pune. I have done BE in Computer\n",
      "AI:  Hi Sanjay, it's nice to meet you. I'm an AI and I'm programmed to answer questions about Pune. Can I help you with anything?\n",
      "Human: Do you mind telling me full form of AI?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure, AI stands for Artificial Intelligence. It is a branch of computer science that focuses on creating intelligent machines that can think and act like humans.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Do you mind telling me full form of AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d956faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Sanjay, I am currently staying Pune. I have done BE in Computer\n",
      "AI:  Hi Sanjay, it's nice to meet you. I'm an AI and I'm programmed to answer questions about Pune. Can I help you with anything?\n",
      "Human: Do you mind telling me full form of AI?\n",
      "AI:  Sure, AI stands for Artificial Intelligence. It is a branch of computer science that focuses on creating intelligent machines that can think and act like humans.\n",
      "Human: What is India capital?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" India's capital is New Delhi.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"What is India capital?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eec0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Sanjay, I am currently staying Pune. I have done BE in Computer\n",
      "AI:  Hi Sanjay, it's nice to meet you. I'm an AI and I'm programmed to answer questions about Pune. Can I help you with anything?\n",
      "Human: Do you mind telling me full form of AI?\n",
      "AI:  Sure, AI stands for Artificial Intelligence. It is a branch of computer science that focuses on creating intelligent machines that can think and act like humans.\n",
      "Human: What is India capital?\n",
      "AI:  India's capital is New Delhi.\n",
      "Human: Who is USA president?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  The current President of the United States is Joe Biden.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Who is USA president?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa582bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Sanjay, I am currently staying Pune. I have done BE in Computer\n",
      "AI:  Hi Sanjay, it's nice to meet you. I'm an AI and I'm programmed to answer questions about Pune. Can I help you with anything?\n",
      "Human: Do you mind telling me full form of AI?\n",
      "AI:  Sure, AI stands for Artificial Intelligence. It is a branch of computer science that focuses on creating intelligent machines that can think and act like humans.\n",
      "Human: What is India capital?\n",
      "AI:  India's capital is New Delhi.\n",
      "Human: Who is USA president?\n",
      "AI:   The current President of the United States is Joe Biden.\n",
      "Human: Have I done my BE in Electonics?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' No, you said you have done BE in Computer.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Have I done my BE in Electonics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc30b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
