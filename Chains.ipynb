{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba383f1",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cb62c",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain\n",
    "The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837ee668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b25952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc7689ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = OpenAI(temperature=.1)\n",
    "template = \"\"\"Who is the president of the {country} ?\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"], template=template)\n",
    "capital_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "145f9c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7164c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.1)\n",
    "template = \"\"\"What is the birth date of {president}?\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"president\"], template=template)\n",
    "bdate_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42da2e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[capital_chain, bdate_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b9cf843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The current President of India is Ram Nath Kovind.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Ram Nath Kovind was born on October 1, 1945.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc1630c",
   "metadata": {},
   "source": [
    "## SequentialChain \n",
    "A more general form of sequential chains, allowing for multiple inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9618cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aee7ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Could you add few lines about {topic} and {subtopic}?\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"topic\", \"subtopic\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"synopsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92a2fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Summarise the following synopsis to one line: {synopsis} \"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "summary_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"oneLine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4937641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"Translate the following synopsis to spanish:  {synopsis}\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "hindi_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"hindisynopsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c9e8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain,hindi_chain, summary_chain],\n",
    "    input_variables=[\"topic\", \"subtopic\"],\n",
    "    output_variables=[\"synopsis\", \"hindisynopsis\", \"oneLine\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0496b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': 'Spain',\n",
       " 'subtopic': 'Economy',\n",
       " 'synopsis': \"\\n\\nSpain has a diversified and advanced economy, with services representing the largest sector (contributing around 70% of GDP), followed by industry (26%) and agriculture (4%). The country's main industries include automotive, textiles, tourism, energy, chemicals, food and beverages, electronics, telecommunications, construction, and shipbuilding. Spain also has a strong presence in the production of renewable energy, such as wind and solar power. The country is a member of the European Union, which has had a positive impact on Spain's economy, with increased investments, foreign trade, and employment opportunities. In 2020, Spain's GDP grew by 5.6%, making it one of the fastest-growing economies in the Eurozone.\",\n",
       " 'hindisynopsis': '\\n\\nEspaña tiene una economía diversificada y avanzada, con servicios que representan el sector más grande (contribuyendo alrededor del 70% del PIB), seguido por la industria (26%) y la agricultura (4%). Las principales industrias del país incluyen automotriz, textiles, turismo, energía, químicos, alimentos y bebidas, electrónica, telecomunicaciones, construcción y astilleros. España también tiene una fuerte presencia en la producción de energía renovable, como la energía eólica y solar. El país es miembro de la Unión Europea, lo que ha tenido un impacto positivo en la economía de España, con aumentos de inversiones, comercio exterior y oportunidades de empleo. En 2020, el PIB de España creció un 5,6%, lo que lo convierte en una de las economías con mayor crecimient',\n",
       " 'oneLine': '\\n\\nSpain has a diversified and advanced economy with a focus on services, industry, agriculture, automotive, textiles, tourism, energy, chemicals, food and beverages, electronics, telecommunications, construction, shipbuilding, and renewable energy, and has seen strong economic growth as a member of the European Union.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain({\"topic\":\"Spain\", \"subtopic\": \"Economy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47f444",
   "metadata": {},
   "source": [
    "## LoadSummarize chain\n",
    "\n",
    "This is the fundamental chain to perform the task of summarization over documents.\n",
    "\n",
    "### Map reduce\n",
    "The map reduce documents chain first applies an LLM chain to each document individually, treating the chain output as a new document. It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step). It can optionally first compress, or collapse, the mapped documents to make sure that they fit in the combine documents chain (which will often pass them to an LLM). This compression step is performed recursively if necessary.\n",
    "\n",
    "This algorithm works by first splitting the entire input into small chunks using a text splitter. Then we create a summary of each of these chunks. Once we get a summary of each, the algorithm creates a summary over these summaries and provides an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cb4d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ae164d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "texts = text_splitter.split_text(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2185b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca51fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b84fafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' President Biden has outlined a Unity Agenda for the Nation, which includes tackling the opioid epidemic, mental health issues, and supporting veterans. In response to Russian aggression in Ukraine, the US and its allies are taking action to seize ill-gotten gains and isolate them economically. The US is also providing military, economic, and humanitarian assistance to Ukraine. The American Rescue Plan and the Bipartisan Infrastructure Law have been passed to help Americans struggling with the pandemic and to create jobs. The President is also pushing for the passage of the Bipartisan Innovation Act, which would make record investments in emerging technologies and American manufacturing. He is encouraging the use of American products to support American jobs and is proposing a global minimum tax rate to prevent companies from avoiding taxes. Finally, he is calling for Americans to come together and move forward on COVID-19 and other issues.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "chain.run( docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa34045",
   "metadata": {},
   "source": [
    "# Router\n",
    "Router chain dynamically selects the next chain to use for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "37594ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2554c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9ce7070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04640ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ba5e2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "521bfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23a91440",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "023afad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': \"What is Newton's third law?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Newton's third law states that for every action, there is an equal and opposite reaction. In other words, the forces between two objects always come in pairs, and these forces are equal in magnitude and opposite in direction.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is Newtons third law?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab7f9d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the largest three digit prime number?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The largest three digit prime number is 997.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is the largest 3 digit prime number?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bdc865be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Where did the First World War take place?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "I do not know the answer to this question, as it is outside the scope of my expertise in physics.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"Where did the First World War take place?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f15475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
